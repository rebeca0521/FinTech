{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 輸入關鍵字\n",
    "* 輸入想要查找的關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the keyword:防疫概念股\n"
     ]
    }
   ],
   "source": [
    "keyword = input(\"Please enter the keyword:\")\n",
    "site = 'www.ettoday.net'\n",
    "# site = input(\"Which media you want to access: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jack1563311/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: use options instead of chrome_options\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import codecs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\n",
    "    'profile.default_content_setting_values': {\n",
    "        'images': 2,\n",
    "        'javascript': 2\n",
    "    }\n",
    "}\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome('./chromedriver', chrome_options=options)\n",
    "# 開啟google網頁\n",
    "driver.get(\"https://www.google.com\")\n",
    "driver.implicitly_wait(10)\n",
    "# 輸入關鍵字、檢索\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"tsf\"]/div[2]/div[1]/div[1]/div/div[2]/input\"\"\").click()\n",
    "driver.implicitly_wait(1)\n",
    "\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"tsf\"]/div[2]/div[1]/div[1]/div/div[2]/input\"\"\").clear()\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"tsf\"]/div[2]/div[1]/div[1]/div/div[2]/input\"\"\").send_keys(keyword+' site:'+site)\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"tsf\"]/div[2]/div[1]/div[1]/div/div[2]/input\"\"\").send_keys(Keys.ENTER)\n",
    "driver.implicitly_wait(5)\n",
    "# 進階搜尋：keyword、特定網域、特定時間\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"st-toggle\"]\"\"\").click()  # 進階搜索\n",
    "# 輸入關鍵字\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"xX4UFf\"]\"\"\").click()\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"xX4UFf\"]\"\"\").send_keys(keyword)\n",
    "# 輸入網域\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"NqEkZd\"]\"\"\").click()\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"NqEkZd\"]\"\"\").send_keys(site)\n",
    "# 輸入時間\n",
    "driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[5]/form/div[5]/div[3]/div[2]/div/select\"\"\").click()\n",
    "driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[5]/form/div[5]/div[3]/div[2]/div/select/option[5]\"\"\").click()  # option[4]是最近一個月內\n",
    "### 若將上面option[4]改為5將可搜得最近1年的資料\n",
    "driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[5]/form/div[5]/div[9]/div[2]/input\"\"\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自動化流程之迴圈\n",
    "* 請輸入檔案名稱(要加.csv)\n",
    "* 不需另外新建檔案，此迴圈會自動設立csv檔並將內容寫入csv檔中\n",
    "* 過程會需要一點時間，請耐心等候\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請(在您當前的資料夾中)輸入檔案儲存名稱(+.csv)：防疫概念股(re).csv\n",
      "該則新聞無法抓取時間：265\n",
      "該則新聞無法抓取時間：275\n",
      "資料已存取\n"
     ]
    }
   ],
   "source": [
    "location = input(\"請(在您當前的資料夾中)輸入檔案儲存名稱(+.csv)：\")\n",
    "if os.path.exists(location):\n",
    "    df = pd.read_csv(location, header=0)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['title', 'original_text', 'time'])\n",
    "\n",
    "for j in range(50):  # 跑十頁\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    links = soup.select('.kCrYT')  # 只select html的原始碼\n",
    "    count = 0  # 迴圈計數器\n",
    "    news = []  # \n",
    "    for link in links:\n",
    "        count += 1\n",
    "        try:\n",
    "            news.append(link.a['href'])\n",
    "        except:\n",
    "            continue\n",
    "    L = []\n",
    "    for i in range(len(news)):  # 將單一頁數的所有新聞裝進L\n",
    "        try:\n",
    "            r = requests.get(news[i][7:])\n",
    "            news_url = news[i][7:]\n",
    "        except:\n",
    "            r = requests.get(news[i])\n",
    "            news_url = news[i]\n",
    "        news_try = requests.get(news_url)\n",
    "        soup = BeautifulSoup(news_try.text, 'html.parser')\n",
    "        try:\n",
    "            titles = soup.h1.text\n",
    "            stories = soup.select(\".story\")\n",
    "            L.append([])\n",
    "            L[i].append(titles)\n",
    "            # 先對文字做預處理，去除換行以及回到開頭(\\n,\\r)\n",
    "            pattern = '[\\u4e00-\\u9fa5]+'\n",
    "            words = re.findall(pattern, stories[0].text.replace('\\r', '').replace('\\n', ''))\n",
    "            sentence = ''\n",
    "            for word in words:\n",
    "                sentence += word\n",
    "            L[i].append(sentence)\n",
    "            L[i].append(soup.time.text[61:78])\n",
    "            singlepage_df = pd.DataFrame(L, columns=['title', 'original_text', 'time'])\n",
    "        except:\n",
    "            continue\n",
    "    df = df.append(singlepage_df, ignore_index = True)\n",
    "    \n",
    "    if j == 0:\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"main\"]/footer/div[1]/div/div/a\"\"\").click()\n",
    "    else:\n",
    "        try:\n",
    "            try:\n",
    "                driver.find_element_by_xpath(f\"\"\"//*[@id=\"main\"]/footer/div[1]/div/div/a[{j + 1}]/span\"\"\").click()\n",
    "            except:\n",
    "                driver.find_element_by_xpath(f\"\"\"//*[@id=\"main\"]/footer/div[1]/div/div/a[3]/span\"\"\").click()\n",
    "        except:\n",
    "            break\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "droplist = []\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        if int(df['time'][i][:4]) < 2020:\n",
    "            droplist.append(i)\n",
    "    except:\n",
    "        print('該則新聞無法抓取：'+str(count))\n",
    "    count+=1\n",
    "    \n",
    "csvFile = open(location, 'a' ,encoding='utf-8')\n",
    "df.drop(droplist).to_csv(csvFile, mode = 'a', columns=['title', 'original_text', 'time'], encoding='utf-8')\n",
    "print(\"資料已存取\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
